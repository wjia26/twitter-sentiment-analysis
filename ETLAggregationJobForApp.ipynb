{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Job will be uploaded to lambda and run twice a day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pythena\n",
    "import datetime\n",
    "import json\n",
    "import s3fs\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "athena_client = pythena.Athena(\"twitterappdatalake\",region=\"ap-southeast-2\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:/Users/William Jiang/Documents/credentials.json\") as f:\n",
    "    d = json.load(f)\n",
    "    cred_json=d[\"twitter_api\"]\n",
    "    s3_cred_json=d[\"s3-access\"]\n",
    "    \n",
    "##auth using s3fs\n",
    "fs = s3fs.S3FileSystem(anon=False, key=s3_cred_json['ACCESS_KEY_ID'], secret=s3_cred_json['SECRET_ACCESS_KEY'],default_fill_cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Custome Aggregation function. takes in numpy array\n",
    "def word_freq(arr):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_substring=['#','@','&',\"rt\",\"https\",\"https.\",\"t.co\"]\n",
    "    stop_words.update([\"rt\",\"https\",\"https.\",\"-\",'.',':'])\n",
    "    text = \" \".join(str(tweet).lower() for tweet in arr)\n",
    "    all_freq={}\n",
    "    for word in text.split():\n",
    "        #Set the substring flag - if any substring is found then it won't get passed\n",
    "        substring_flag=0\n",
    "        for substring in stop_substring:\n",
    "            if substring in word:\n",
    "                substring_flag=1\n",
    "        if substring_flag==0:\n",
    "            if word not in stop_words:\n",
    "                if word in all_freq: \n",
    "                    all_freq[word] += 1\n",
    "                else: \n",
    "                    all_freq[word] = 1   \n",
    "    word_freq_list=sorted(all_freq.items(), key=lambda x: x[1],reverse=True)[0:30]\n",
    "    return word_freq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_to_agg_df(string_date):\n",
    "    string_query='''\n",
    "    SELECT * FROM twitterdatalake t where date(date_parse(created_at,'%Y-%m-%d %H:%i:%s'))=date_parse('{0}','%Y-%m-%d')\n",
    "    '''.format(string_date)\n",
    "    df_oneday = athena_client.execute(string_query)\n",
    "    dftest=df_oneday[0]\n",
    "    df_word_freq_groupby=dftest.groupby(['partition_1','partition_0'])['text'].agg([word_freq,'count'])\n",
    "    df_avg_groupby=dftest.groupby(['partition_1','partition_0'])['polarity','followers','friends','retweet_count'].mean()\n",
    "    #join\n",
    "    df_final_agg=df_avg_groupby.join(df_word_freq_groupby, on=['partition_1','partition_0'])\n",
    "    df_final_agg=df_final_agg.rename(columns={\"text\": \"word_freq_list\",\"polarity\": \"avg_polarity\",\"followers\":\"avg_followers\",\"friends\":\"avg_friends\",\"retweet_count\":\"avg_retweet_count\"})\n",
    "    \n",
    "    return df_final_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Key': 'aggregatedresultsforapp/2020-07-22.csv', 'LastModified': datetime.datetime(2020, 7, 28, 10, 7, 4, tzinfo=tzutc()), 'ETag': '\"b24abf1db77e66c95f8b53d9491fb7b8\"', 'Size': 166774, 'StorageClass': 'STANDARD', 'type': 'file', 'size': 166774, 'name': 'aggregatedresultsforapp/2020-07-22.csv'}\n",
      "{'Key': 'aggregatedresultsforapp/2020-07-23.csv', 'LastModified': datetime.datetime(2020, 7, 28, 10, 18, 39, tzinfo=tzutc()), 'ETag': '\"707c34c8f79739f24c90f0258d552b69\"', 'Size': 174512, 'StorageClass': 'STANDARD', 'type': 'file', 'size': 174512, 'name': 'aggregatedresultsforapp/2020-07-23.csv'}\n",
      "{'Key': 'aggregatedresultsforapp/2020-07-24.csv', 'LastModified': datetime.datetime(2020, 7, 28, 10, 31, 55, tzinfo=tzutc()), 'ETag': '\"beede18237886661bd10c5b11c0cf840\"', 'Size': 164145, 'StorageClass': 'STANDARD', 'type': 'file', 'size': 164145, 'name': 'aggregatedresultsforapp/2020-07-24.csv'}\n"
     ]
    }
   ],
   "source": [
    "for file in fs.listdir('aggregatedresultsforapp'):\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-24\n"
     ]
    }
   ],
   "source": [
    "# string_today=today_date.strftime(\"%Y-%m-%d\")\n",
    "max_date=datetime.datetime.strptime(\"2020-07-13\", \"%Y-%m-%d\").date()\n",
    "#Find the max date in the s3 bucket\n",
    "for file in fs.listdir('aggregatedresultsforapp'):\n",
    "    current_string=file['Key'].split('/')[-1].split('.csv')[0]\n",
    "    current_date=datetime.datetime.strptime(current_string, \"%Y-%m-%d\").date()\n",
    "    if current_date>max_date:\n",
    "        max_date=current_date\n",
    "\n",
    "print(max_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.00192832946777\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "day_before_date = datetime.date.today() - datetime.timedelta(days=2)\n",
    "#If less than daybeforedate then ingest the next date else leave alone\n",
    "if max_date<day_before_date:\n",
    "    next_date=max_date + datetime.timedelta(days=1)\n",
    "    str_next_date=next_date.strftime(\"%Y-%m-%d\")\n",
    "    df_final_agg=query_to_agg_df(str_next_date)\n",
    "    file_dir='s3://aggregatedresultsforapp/'\n",
    "    full_filename=file_dir+ str_next_date\n",
    "    with fs.open(full_filename+ '.csv','w', encoding=\"utf-8\", newline = '\\n') as f:\n",
    "        df_final_agg.to_csv(f)\n",
    "\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
